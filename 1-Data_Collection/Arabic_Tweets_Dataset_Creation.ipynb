{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Arabic Tweets",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4ndp3Ix-FoQn",
        "outputId": "442d7371-5c76-4f1d-c23b-f383bf1a02e5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/drive/MyDrive/3oumara\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mPlFCeCpFqPF",
        "outputId": "ce95cc94-623f-435c-a6ff-4f7fc4b58921"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/3oumara\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pwd"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_zesNbZpGh_t",
        "outputId": "a17a9513-d155-4b2f-d1ba-dc6696cc1a7b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/My Drive/3oumara/arabic-sentiment-analysis/arabic_tweets_json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/motazsaad/arabic-sentiment-analysis.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bxQrRPumGjJG",
        "outputId": "fe37bac8-0fb1-4ab1-bc4c-4dac8019b678"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'arabic-sentiment-analysis'...\n",
            "remote: Enumerating objects: 296, done.\u001b[K\n",
            "remote: Counting objects: 100% (8/8), done.\u001b[K\n",
            "remote: Compressing objects: 100% (8/8), done.\u001b[K\n",
            "remote: Total 296 (delta 0), reused 0 (delta 0), pack-reused 288\u001b[K\n",
            "Receiving objects: 100% (296/296), 453.69 MiB | 20.29 MiB/s, done.\n",
            "Resolving deltas: 100% (135/135), done.\n",
            "Checking out files: 100% (83/83), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd arabic-sentiment-analysis/arabic_tweets_json"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gQ0qQ2UxHc0B",
        "outputId": "fedd74bc-f87a-41fa-b889-086ab74d5d8d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/3oumara/arabic-sentiment-analysis/arabic_tweets_json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip \"./positive_tweets_arabic_20181207_300.zip\" -d \"./unzipped_dataset\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K6o4qPt0KiIr",
        "outputId": "743ffccd-7d48-4c61-ef72-f44822499cc3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  ./positive_tweets_arabic_20181207_300.zip\n",
            "  inflating: ./unzipped_dataset/positive_tweets_arabic_20181207_300.json  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os,json"
      ],
      "metadata": {
        "id": "s3rrJb-bGsph"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "path_to_json = './unzipped_dataset'\n",
        "json_files = [pos_json for pos_json in os.listdir(path_to_json) if pos_json.endswith('.json')]\n",
        "print(json_files)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kvw__wIwGwdP",
        "outputId": "74649896-d8ad-4a9f-b42e-95f04066d9ef"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Arabic_tweets_negative_20190413.json', 'Arabic_tweets_positive_20190413.json', 'negative_tweets_arabic_20181206_1k.json', 'negative_tweets_arabic_20181207_100.json', 'negative_tweets_arabic_20181207_300.json', 'positive_tweets_arabic_20181206_1k.json', 'positive_tweets_arabic_20181206_4k.json', 'positive_tweets_arabic_20181207_100.json', 'positive_tweets_arabic_20181207_300.json']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "In the next cell we have an example of reading the content of 1 json file and displaying ID of each tweet"
      ],
      "metadata": {
        "id": "9N0XsaN7G-le"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with open('Arabic_tweets_negative_20190413.json') as json_test:\n",
        "    for line in json_test:\n",
        "        json_text_test = json.loads(line)\n",
        "        print(json_text_test['id'])\n",
        "        print(index)"
      ],
      "metadata": {
        "id": "Mstjss31G1_T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open('Arabic_tweets_negative_20190413.json') as json_test:\n",
        "    for index, line in enumerate(json_test):\n",
        "        json_text_test = json.loads(line)\n",
        "        print(json_text_test['id'])\n",
        "        print(index)"
      ],
      "metadata": {
        "id": "nmYmNsBPG3ya"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here we create a dataframe from 1 json file, where we have ID,Text,createdAt"
      ],
      "metadata": {
        "id": "thwoOPzvHBpr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import re"
      ],
      "metadata": {
        "id": "EmwF1vPvG7D0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_test_one = pd.DataFrame(columns=['id', 'text', 'createdAt'])\n"
      ],
      "metadata": {
        "id": "WjhqtsQVHEKC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open('Arabic_tweets_negative_20190413.json') as json_test:\n",
        "    for index, line in enumerate(json_test):\n",
        "        json_text_test = json.loads(line)\n",
        "        id_test = json_text_test['id']\n",
        "        text_test = json_text_test['text']\n",
        "        created_at_test = json_text_test['created_at']\n",
        "        \n",
        "        df_test_one.loc[index] = [id_test,text_test,created_at_test]\n",
        "        "
      ],
      "metadata": {
        "id": "axcLdkyuHFS_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_test_one"
      ],
      "metadata": {
        "id": "X6vn8JKDHHPv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tweets_df = pd.DataFrame(columns=['id', 'text', 'createdAt'])\n",
        "tweet_count_total=0\n",
        "for file_index, js in enumerate(json_files):\n",
        "    tweet_count_per_file=0\n",
        "    with open(os.path.join(path_to_json, js)) as json_file:\n",
        "        print(f\"Opened File {file_index}\")\n",
        "        for tweet_index, line in enumerate(json_file):\n",
        "            tweet = json.loads(line)\n",
        "            tweet_id = tweet['id']\n",
        "            #here we do some cleaning for text, keeping only arabic letters and numbers and 1 whitespace\n",
        "            tweet_text = re.sub(r'[^0-9\\u0600-\\u06ff\\u0750-\\u077f\\ufb50-\\ufbc1\\ufbd3-\\ufd3f\\ufd50-\\ufd8f\\ufd50-\\ufd8f\\ufe70-\\ufefc\\uFDF0-\\uFDFD- ]+', '', tweet['text'])\n",
        "            tweet_created_at = tweet['created_at']\n",
        "            \n",
        "            tweets_df.loc[tweet_count_total] = [tweet_id,tweet_text,tweet_created_at]\n",
        "            \n",
        "            tweet_count_total+=1\n",
        "            tweet_count_per_file+=1\n",
        "        print(f\"Tweet count for file {file_index} is  : {tweet_count_per_file} \")\n",
        "        print(f\"Total number of tweets : {tweet_count_total}\")\n",
        "        print(f\"Ended file {file_index}\\n \")\n",
        "        index_current_file = tweet_count_total - tweet_count_per_file\n",
        "        tweets_df.iloc[ index_current_file:tweet_count_total ,:].to_csv(''.join([\"./unzipped_dataset/dataset_csv/\",str(js), '_cleaned','.csv']))\n",
        "        print(\"Wrote dataframe of file {file_index} to CSV\")\n",
        "\n",
        "        \n",
        "tweets_df.to_csv('./unzipped_dataset/dataset_csv/tweets_drop_cols_cleaned_text.csv')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "q-n6ytgaHQ-b",
        "outputId": "1099765f-1c3a-4526-cbe3-02d0e5ae3ac4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Opened File 0\n",
            "Tweet count for file 0 is  : 40000 \n",
            "Total number of tweets : 40000\n",
            "Ended file 0\n",
            " \n",
            "Wrote dataframe of file {file_index} to CSV\n",
            "Opened File 1\n",
            "Tweet count for file 1 is  : 40000 \n",
            "Total number of tweets : 80000\n",
            "Ended file 1\n",
            " \n",
            "Wrote dataframe of file {file_index} to CSV\n",
            "Opened File 2\n",
            "Tweet count for file 2 is  : 30969 \n",
            "Total number of tweets : 110969\n",
            "Ended file 2\n",
            " \n",
            "Wrote dataframe of file {file_index} to CSV\n",
            "Opened File 3\n",
            "Tweet count for file 3 is  : 18041 \n",
            "Total number of tweets : 129010\n",
            "Ended file 3\n",
            " \n",
            "Wrote dataframe of file {file_index} to CSV\n",
            "Opened File 4\n",
            "Tweet count for file 4 is  : 14679 \n",
            "Total number of tweets : 143689\n",
            "Ended file 4\n",
            " \n",
            "Wrote dataframe of file {file_index} to CSV\n",
            "Opened File 5\n",
            "Tweet count for file 5 is  : 22988 \n",
            "Total number of tweets : 166677\n",
            "Ended file 5\n",
            " \n",
            "Wrote dataframe of file {file_index} to CSV\n",
            "Opened File 6\n",
            "Tweet count for file 6 is  : 44037 \n",
            "Total number of tweets : 210714\n",
            "Ended file 6\n",
            " \n",
            "Wrote dataframe of file {file_index} to CSV\n",
            "Opened File 7\n",
            "Tweet count for file 7 is  : 20357 \n",
            "Total number of tweets : 231071\n",
            "Ended file 7\n",
            " \n",
            "Wrote dataframe of file {file_index} to CSV\n",
            "Opened File 8\n",
            "Tweet count for file 8 is  : 6891 \n",
            "Total number of tweets : 237962\n",
            "Ended file 8\n",
            " \n",
            "Wrote dataframe of file {file_index} to CSV\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-26-9868a2324bb7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m \u001b[0mtweets_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'./dataset_csv/tweets_drop_cols_cleaned_text.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36mto_csv\u001b[0;34m(self, path_or_buf, sep, na_rep, float_format, columns, header, index, index_label, mode, encoding, compression, quoting, quotechar, line_terminator, chunksize, date_format, doublequote, escapechar, decimal, errors)\u001b[0m\n\u001b[1;32m   3168\u001b[0m             \u001b[0mdecimal\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdecimal\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3169\u001b[0m         )\n\u001b[0;32m-> 3170\u001b[0;31m         \u001b[0mformatter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3171\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3172\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mpath_or_buf\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/formats/csvs.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    188\u001b[0m                 \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m                 \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 190\u001b[0;31m                 \u001b[0mcompression\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompression_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompression\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    191\u001b[0m             )\n\u001b[1;32m    192\u001b[0m             \u001b[0mclose\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors)\u001b[0m\n\u001b[1;32m    491\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    492\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 493\u001b[0;31m             \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_or_buf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnewline\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    494\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mis_text\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m             \u001b[0;31m# No explicit encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './dataset_csv/tweets_drop_cols_cleaned_text.csv'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tweets_df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "6muNpBmpis1c",
        "outputId": "8615dc82-c1e6-483b-c94e-83ecfca54413"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>text</th>\n",
              "      <th>createdAt</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1116941759764992000</td>\n",
              "      <td>34 رحمه الله رحمه واسعه واسكنه فسيح جناته</td>\n",
              "      <td>Sat Apr 13 05:50:41 +0000 2019</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1116941758300995584</td>\n",
              "      <td>1978 ماعندك  حجه لذلك تتهمين الكل بأنه ينتمي ...</td>\n",
              "      <td>Sat Apr 13 05:50:41 +0000 2019</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1116941764047273989</td>\n",
              "      <td>راح فين كلامك الي كنتي بتقوليه رايكو في صوتي 52</td>\n",
              "      <td>Sat Apr 13 05:50:42 +0000 2019</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1116941765305565184</td>\n",
              "      <td>2019 كلام اهلها انهم دخلوها مستشفى الامل لمدة...</td>\n",
              "      <td>Sat Apr 13 05:50:43 +0000 2019</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1116941765385310209</td>\n",
              "      <td>ليش عم تسبنا يامخرف</td>\n",
              "      <td>Sat Apr 13 05:50:43 +0000 2019</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>237957</th>\n",
              "      <td>1070871736558764034</td>\n",
              "      <td>اطلق صباح</td>\n",
              "      <td>Fri Dec 07 02:44:52 +0000 2018</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>237958</th>\n",
              "      <td>1070871389639454720</td>\n",
              "      <td>ي ايماااي نورت تويتر يستا</td>\n",
              "      <td>Fri Dec 07 02:43:29 +0000 2018</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>237959</th>\n",
              "      <td>1070870698418155520</td>\n",
              "      <td>3 هتوحشيني</td>\n",
              "      <td>Fri Dec 07 02:40:44 +0000 2018</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>237960</th>\n",
              "      <td>1070870025802797056</td>\n",
              "      <td>1 اللهم يحميكم وينصركم وتعودا لنا بالصحه والعا...</td>\n",
              "      <td>Fri Dec 07 02:38:04 +0000 2018</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>237961</th>\n",
              "      <td>1070869632666558464</td>\n",
              "      <td>انتي قلبي والله يا بيبا</td>\n",
              "      <td>Fri Dec 07 02:36:30 +0000 2018</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>237962 rows × 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                         id  ...                       createdAt\n",
              "0       1116941759764992000  ...  Sat Apr 13 05:50:41 +0000 2019\n",
              "1       1116941758300995584  ...  Sat Apr 13 05:50:41 +0000 2019\n",
              "2       1116941764047273989  ...  Sat Apr 13 05:50:42 +0000 2019\n",
              "3       1116941765305565184  ...  Sat Apr 13 05:50:43 +0000 2019\n",
              "4       1116941765385310209  ...  Sat Apr 13 05:50:43 +0000 2019\n",
              "...                     ...  ...                             ...\n",
              "237957  1070871736558764034  ...  Fri Dec 07 02:44:52 +0000 2018\n",
              "237958  1070871389639454720  ...  Fri Dec 07 02:43:29 +0000 2018\n",
              "237959  1070870698418155520  ...  Fri Dec 07 02:40:44 +0000 2018\n",
              "237960  1070870025802797056  ...  Fri Dec 07 02:38:04 +0000 2018\n",
              "237961  1070869632666558464  ...  Fri Dec 07 02:36:30 +0000 2018\n",
              "\n",
              "[237962 rows x 3 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tweets_df.to_csv('./unzipped_dataset/dataset_csv/tweets_drop_cols_cleaned_text.csv')"
      ],
      "metadata": {
        "id": "qjcpW3P8mffO"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}